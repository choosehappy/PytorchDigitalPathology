{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "jJu3WmHyaPSA"
            },
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/gdrive')\n",
                "%cd /gdrive/My\\ Drive/PytorchDigitalPathology/google-collab-version/PytorchDigitalPathology/segmentation_epistroma_unet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "R4hJyv59mMRb"
            },
            "outputs": [],
            "source": [
                "import sklearn\n",
                "import torch\n",
                "import argparse\n",
                "import numpy as np\n",
                "import cv2\n",
                "import torchvision\n",
                "from PS_scikitlearn import extract_patches\n",
                "from unet import UNet\n",
                "import os, glob"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "b10eg38fqen8"
            },
            "outputs": [],
            "source": [
                "#-----helper function to split data into batches\n",
                "def divide_batch(l, n): \n",
                "    for i in range(0, l.shape[0], n):  \n",
                "        yield l[i:i + n,::] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "1i-nJgOlqlI-"
            },
            "outputs": [],
            "source": [
                "# ----- parse command line arguments\n",
                "parser = argparse.ArgumentParser(description='Make output for entire image using Unet')\n",
                "parser.add_argument('input_pattern',\n",
                "                    help=\"input filename pattern. try: *.png, or tsv file containing list of files to analyze\",\n",
                "                    nargs=\"*\")\n",
                "\n",
                "parser.add_argument('-p', '--patchsize', help=\"patchsize, default 256\", default=256, type=int)\n",
                "parser.add_argument('-s', '--batchsize', help=\"batchsize for controlling GPU memory usage, default 10\", default=10, type=int)\n",
                "parser.add_argument('-o', '--outdir', help=\"outputdir, default ./output/\", default=\"./output/\", type=str)\n",
                "parser.add_argument('-r', '--resize', help=\"resize factor 1=1x, 2=2x, .5 = .5x\", default=1, type=float)\n",
                "parser.add_argument('-m', '--model', help=\"model\", default=\"best_model.pth\", type=str)\n",
                "parser.add_argument('-i', '--gpuid', help=\"id of gpu to use\", default=0, type=int)\n",
                "parser.add_argument('-f', '--force', help=\"force regeneration of output even if it exists\", default=False,\n",
                "                    action=\"store_true\")\n",
                "parser.add_argument('-b', '--basepath',\n",
                "                    help=\"base path to add to file names, helps when producing data using tsv file as input\",\n",
                "                    default=\"\", type=str)\n",
                "\n",
                "# args = parser.parse_args()\n",
                "args = parser.parse_args([\"./data/*.tif\",\"-o./data/output\",\"-m./epistroma_unet_best_model.pth\"] )\n",
                "\n",
                "if not (args.input_pattern):\n",
                "    parser.error('No images selected with input pattern')\n",
                "\n",
                "OUTPUT_DIR = args.outdir\n",
                "resize = args.resize\n",
                "\n",
                "batch_size = args.batchsize\n",
                "patch_size = args.patchsize\n",
                "stride_size = patch_size//2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "wTOrajwrAoP0"
            },
            "outputs": [],
            "source": [
                "# ----- load network\n",
                "device = torch.device(args.gpuid if torch.cuda.is_available() else 'cpu')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GcFBci8NAsXT"
            },
            "outputs": [],
            "source": [
                "checkpoint = torch.load(args.model, map_location=lambda storage, loc: storage) \n",
                "#load checkpoint to CPU and then put to device https://discuss.pytorch.org/t/saving-and-loading-torch-models-on-2-machines-with-different-number-of-gpu-devices/6666"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "t2tqNu5GerD9"
            },
            "outputs": [],
            "source": [
                "model = UNet(n_classes=checkpoint[\"n_classes\"], in_channels=checkpoint[\"in_channels\"],\n",
                "             padding=checkpoint[\"padding\"], depth=checkpoint[\"depth\"], wf=checkpoint[\"wf\"],\n",
                "             up_mode=checkpoint[\"up_mode\"], batch_norm=checkpoint[\"batch_norm\"]).to(device)\n",
                "model.load_state_dict(checkpoint[\"model_dict\"])\n",
                "model.eval()\n",
                "\n",
                "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "_Sp1C2x9fI2X"
            },
            "outputs": [],
            "source": [
                "# ----- get file list\n",
                "\n",
                "if not os.path.exists(OUTPUT_DIR):\n",
                "    os.makedirs(OUTPUT_DIR)\n",
                "\n",
                "files = []\n",
                "basepath = args.basepath  #\n",
                "basepath = basepath + os.sep if len(\n",
                "    basepath) > 0 else \"\"  # if the user supplied a different basepath, make sure it ends with an os.sep\n",
                "\n",
                "if len(args.input_pattern) > 1:  # bash has sent us a list of files\n",
                "    files = args.input_pattern\n",
                "elif args.input_pattern[0].endswith(\"tsv\"):  # user sent us an input file\n",
                "    # load first column here and store into files\n",
                "    with open(args.input_pattern[0], 'r') as f:\n",
                "        for line in f:\n",
                "            if line[0] == \"#\":\n",
                "                continue\n",
                "            files.append(basepath + line.strip().split(\"\\t\")[0])\n",
                "else:  # user sent us a wildcard, need to use glob to find files\n",
                "    if len(args.basepath)>=1:\n",
                "      files = glob.glob(args.basepath +\"/\"+ args.input_pattern[0])\n",
                "    else:\n",
                "      files = glob.glob(args.input_pattern[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "EdgMBu1pniRc"
            },
            "outputs": [],
            "source": [
                "# ------ work on files\n",
                "for fname in files:\n",
                "\n",
                "    fname = fname.strip()\n",
                "    newfname_class = \"%s/%s_class.png\" % (OUTPUT_DIR, os.path.basename(fname)[0:os.path.basename(fname).rfind(\".\")])\n",
                "\n",
                "    print(f\"working on file: \\t {fname}\")\n",
                "    print(f\"saving to : \\t {newfname_class}\")\n",
                "\n",
                "    if not args.force and os.path.exists(newfname_class):\n",
                "        print(\"Skipping as output file exists\")\n",
                "        continue\n",
                "\n",
                "    cv2.imwrite(newfname_class, np.zeros(shape=(1, 1)))\n",
                "\n",
                "    \n",
                "    io = cv2.cvtColor(cv2.imread(fname),cv2.COLOR_BGR2RGB)\n",
                "    io = cv2.resize(io, (0, 0), fx=args.resize, fy=args.resize)\n",
                "\n",
                "    io_shape_orig = np.array(io.shape)\n",
                "    \n",
                "    #add half the stride as padding around the image, so that we can crop it away later\n",
                "    io = np.pad(io, [(stride_size//2, stride_size//2), (stride_size//2, stride_size//2), (0, 0)], mode=\"reflect\")\n",
                "    \n",
                "    io_shape_wpad = np.array(io.shape)\n",
                "    \n",
                "    #pad to match an exact multiple of unet patch size, otherwise last row/column are lost\n",
                "    npad0 = int(np.ceil(io_shape_wpad[0] / patch_size) * patch_size - io_shape_wpad[0])\n",
                "    npad1 = int(np.ceil(io_shape_wpad[1] / patch_size) * patch_size - io_shape_wpad[1])\n",
                "\n",
                "    io = np.pad(io, [(0, npad0), (0, npad1), (0, 0)], mode=\"constant\")\n",
                "\n",
                "    arr_out = extract_patches(io,(patch_size,patch_size,3),stride_size)\n",
                "    arr_out_shape = arr_out.shape\n",
                "    arr_out = arr_out.reshape(-1,patch_size,patch_size,3)\n",
                "\n",
                "    #in case we have a large network, lets cut the list of tiles into batches\n",
                "    output = np.zeros((0,checkpoint[\"n_classes\"],patch_size,patch_size))\n",
                "    for batch_arr in divide_batch(arr_out,batch_size):\n",
                "        \n",
                "        arr_out_gpu = torch.from_numpy(batch_arr.transpose(0, 3, 1, 2) / 255).type('torch.FloatTensor').to(device)\n",
                "\n",
                "        # ---- get results\n",
                "        output_batch = model(arr_out_gpu)\n",
                "\n",
                "        # --- pull from GPU and append to rest of output \n",
                "        output_batch = output_batch.detach().cpu().numpy()\n",
                "        \n",
                "        output = np.append(output,output_batch,axis=0)\n",
                "\n",
                "\n",
                "    output = output.transpose((0, 2, 3, 1))\n",
                "    \n",
                "    #turn from a single list into a matrix of tiles\n",
                "    output = output.reshape(arr_out_shape[0],arr_out_shape[1],patch_size,patch_size,output.shape[3])\n",
                "\n",
                "    #remove the padding from each tile, we only keep the center\n",
                "    output=output[:,:,stride_size//2:-stride_size//2,stride_size//2:-stride_size//2,:]\n",
                "\n",
                "    #turn all the tiles into an image\n",
                "    output=np.concatenate(np.concatenate(output,1),1)\n",
                "    \n",
                "    #incase there was extra padding to get a multiple of patch size, remove that as well\n",
                "    output = output[0:io_shape_orig[0], 0:io_shape_orig[1], :] #remove paddind, crop back\n",
                "\n",
                "    # --- save output\n",
                "\n",
                "    # cv2.imwrite(newfname_class, (output.argmax(axis=2) * (256 / (output.shape[-1] - 1) - 1)).astype(np.uint8))\n",
                "    cv2.imwrite(newfname_class, output.argmax(axis=2) * (256 / (output.shape[-1] - 1) - 1))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "tK42ffaSJxgU"
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "make_output_unet_cmd.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
